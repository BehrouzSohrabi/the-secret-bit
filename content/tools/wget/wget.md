---
title: "wget"
date: 2021-09-17T12:27:38+04:30
draft: false
tags: ["wget", "download", "internet", "download-manager", "دانلود", "اینترنت"]
---

<div dir='rtl'>

[![wget](cover.png)](cover.png)

### فهرست
> - [مقدمه](#مقدمه)
> - [دانلود فایل](#دانلود-فایل)
> - [ذخیره با اسم متفاوت](#دانلود-فایل-و-ذخیره-آن-با-یک-اسم-متفاوت)
> - [دانلود در پوشه متفاوت](#دانلود-فایل-و-ذخیره-آن-در-یک-دایرکتوری-مشخص)
> - [دانلود لیستی از فایل های متوالی](#دانلود-لیستی-از-فایل-های-متوالی)
> - [خروجی](#نمایشعدم-نمایش-خروجی)
> - [دانلود از لیست دانلود](#خواندن-لینک-ها-از-فایل-داخلی-یا-از-اینترنت)
> - [ادامه دانلود](#ادامه-دانلود-متوقف-شده-یا-شکست-خورده)
> - [تلاش مجدد](#تلاش-مجدد)
> - [وقفه](#وقفه)
> - [محدود کردن پهنای باند](#محدود-کردن-پهنای-باند)
> - [محدود کردن ترافیک](#محدود-کردن-ترافیک)
> - [دانلود در پس زمینه](#دانلود-در-پس-زمینه)
> - [میرور کردن سایت](#میرور-کردن-سایت)
> - [نکات](#نکته-ها)
> - [پروکسی](#تنطیم-کردن-پروکسی)
> - [دانلود فایل با پسونده مشخص](#دانلود-فایل-با-پسونده-مشخص)

</div>

---

<div dir='rtl'>

### مقدمه
</div>

یکی از ابزار های پر استفاده در دانلود فایل است، سال هاست که دانلود منیجر های گرافیکی و پیشرفته وجود دارند
اما با اینحال به این دلیل که
wget
گزینه های پیشرفته ای دارد، هنوز هم بسیار کاربردی و مفید است.
wget
جز اینکه برای دانلود فایل استفاده می‌شود، برای دانلود یا میرور کردن یک سایت هم استفاده می‌شود.

<div dir='rtl'>

---

### دانلود فایل
</div>

```bash
wget "file_link"
```
برای دانلود چندین فایل به صورت همزمان کافیه لینک ها را با یک فاصله از هم جدا کنید

```bash
wget "link1" "link2" "link3"
```

<div dir='rtl'>

---

### دانلود فایل و ذخیره آن با یک اسم متفاوت
</div>

```bash
‐‐output-document filename.html example.com
```
<div dir='rtl'>

---

### دانلود فایل و ذخیره آن در یک دایرکتوری مشخص
</div>

```bash
‐‐directory-prefix=folder/subfolder example.com
```

---

<div dir='rtl'>

### دانلود لیستی از فایل های متوالی

</div>

گاهی در سرور ها فایل ها را بر اساس ورژن یا تاریخ، در نامشان عدد های متوالی قرار می‌دهند.
برای مثال ممکن است 10 عدد عکس در یک سرور داشته باشیم. که از 1 تا 10 شماره گذاری شده اند،
حال برای دانلود این 10 عدد عکس، به این صورت عمل می‌کنیم.

```bash
wget http://example.com/images/{1..20}.jpg
```

<div dir='rtl'>

---

### نمایش/عدم نمایش خروجی
</div>

زمانی که به یک سرور متصل می‌شوید اتفاقات زیادی رخ می‌دهد ازجمله
error
ها
و
http status code
ها
برای دیدن این اطلاعات باید برنامه را در مود
verbose
قرار داد.

```bash
-v,     --verbose
```

و اگر این اطلاعات نیاز نباشد، چون
wget
به صورت پیشفرض در این حالت قرار دارد، برای خلاص شدن از دیدن این اطلاعات کافیه برنامه زا از حالت
پر حرف منع کرد

```bash
-nv,    --no-verbose
-q,     --quiet
```
اگر نیاز به ذخیره این اطلاعات داشتید باید از سوییچ
`-o FileName.log`
استفاده کنید

نوعی دیگر از خروجی هم وجود دارد که اطلاعات بیشتری را نمایش می‌دهد

```bash
-d,     --debug
```
<div dir='rtl'>

---

### خواندن لینک ها از فایل داخلی یا از اینترنت
</div>

گاهی تعداد لینک ها بیش از تعدادی می‌شود که بشود در ترمینال به نرم افزار داد.
یا ممکن است لینک های دانلود در یک صفحه
html
باشند.

برای اینکه یک فهرست از لینک ها را به صورت یکجا دانلود کنیم، باید از آپشن
```bash
-i "./songs.txt"
--input-file "https://example.com/2077/series/ControlPlustShift/s1/"
```
استفاده کنیم، مقدار این آپشن می‌تواند یک لینک از یک صفحه یا آدرس یک فایل متنی در سیستم شما باشد.
که در هر صورت
wget
تمامی لینک ها را خط به خط به تریب از خط اول دانلود خواهد کرد.

<div dir='rtl'>

---

### ادامه دانلود متوقف شده یا شکست خورده
</div>

به هر دلیلی ممکن است دانلود شکست بخوره، مثل قطعی موقت اینترنت یا داون شدن سرور یا ممکن است که
شما دانلود را متوقف کنید.
برای اینکه دانلود قبلی را ادامه دهید، در همان پوشه ای که فایل نیمه دانلود شده شما قرار دارد، دستور
wget
و لینک فایل را مجدد وارد کنید اما با این تفاوت که شما باید از سوییچ
`-c`
استفاده کنید

```bash
wget -c "last-link"
wget --continue "last-link"
```
<div dir='rtl'>

---

### تلاش مجدد
</div>

اگر
wget
در دانلود فایل شکت بخورد، باز هم دست از تلاش بر نخواهد داشت و بی‌نهایت بار تلاش برای دانلود را ادامه خواهد داد.
اما برای مشخص کردن تعداد تلاش دانلود باید از سوییچ

```bash
-t,     --tries
```
استفاده کرد. اما اگر کانکشن شما به اینترنت قطع شود
wget
دانلود را ادامه نخواهد داد. برای اینکه در این موقعیت هم تلاش برای دانلود متوقف نشود باید با از این سوییچ 
استفاده کرد

```bash
--retry-connrefused
```

ارور های مختلفی وجود دارد که ممکن است هنگام دانلود رخ دهد.
مثل 404 که زمانی رخ می‌دهد که لینک به محتوایی اشاره کند که وجود ندارد.
یا 429 که در مواقعی رخ می‌دهد که شما درخواست های مکرری به سرور سایت داشتید.
و یا 503 که در زمانی رخ می‌دهد که سرور مشغول باشد و توان پردازش درخواست شما را نداشته باشد.
برای مشخص کردن اینکه فقط در زمان وقوع چه ارور هایی تلاش برای دانلود مجدد انجام شود، از این سوییچ استفاده 
می‌شود. توجه داشته باشید که مقدار این سوییچ یک لیست از کد های ارور است که با علامت کاما از هم جدا می‌شوند

```bash
--retry-on-http-error=ERRORS
```

برای اینکه بین هر تلاش مجدد یک وقفه زمانی قرار دهیم از سوییچ
`--waitretry`
استفاده می‌کنیم، زمان بر اساس ثانیه است.

```bash
--waitretry
```
<div dir='rtl'>

---

### وقفه
</div>

برای وقفه گذاشتن بین دانلود ها دو سوییچ داریم. وقفه تصادفی و وقفه طبق زمان مشخص.

وقفه با زمان مشخص. به صورت پیش فرض زمانی که شما مشخص می‌کنید ثانیه است اما با استفاده از پسوند می‌توان
زمان را به دقیقه، ساعت، و روز تغییر داد.

1. m
دقیقه

2. h
ساعت

3. d
روز

```bash
-w 5
--wait 1m
```

وقفه با زمان رندم ممکن است امکان بن شدن شما را کمتر کند. درواقع اگر شما دارید بیشتر از یک فایل را دانلود 
می‌کنید یا تعداد کانکشن زیادی به یک سایت دارید، باید از وقفه استفاده کنید. اگر این وفقه ها زمانی مشخص باشند، ممکن است سایت فعالیت مشکوکی را تشخیص دهد، برای همین بهتر است از وقفه تصادفی استفاده کنید.

```bash
--random-wait 
```
<div dir='rtl'>

---

### محدود کردن پهنای باند
</div>

مواقعی نیاز می‌شود که سرعت دانلود را تا حدی کاهش دهیم، برای مثال زمانی که دیگر افراد می‌خواهند از شبکه
استفاده کنند و ما نباید با مصرف تمامی پهنای باند مزاحم آنها نشویم.
پهنای باند به صورت پیش فرض به بایت تنظیم ‌می‌شود، اما میتوان به کیلوبایت و مگابایت هم تنظیم کرد.

1. k کیلو بایت
2. m مگابایت

```bash
--limit-rate 100k
```

به یاد داشته باشید که حتی می‌توانید از عداد اشاری هم استفاده کنید.

```
--limit-rate 2.5k
```
<div dir='rtl'>

---

### محدود کردن ترافیک
</div>

زمانی که ترافیک قابل مصرف برای شما محدود شده باشد، نیاز پیدا می‌کنید که این محدودیت را برای مواقع
دانلود هم به کار ببرید.

1. k کیلو بایت
2. m مگابایت

```bash
-Q 10k
--quota 1m
```
تنها این را به یاد داشته باشید که این محدودت برای یک فایل اعمال نمی‌شود و فقط زمانی اعمال می‌شود که شما چند
فایل برای دانلود برای
wget
مشخص کرده اید، زمانی که فایل اول کاملا دانلود شد،
wget
میزان ترافیک را محاسبه می‌کند، اگر بیشتر یا مساوی با محدودیت تعیین شده باشد دانلود را متوقف می‌کند.
اگر کمتر باشد دانلود فایل بعدی را ادامه می‌دهد و تا زمانی که دانلود فایل بعدی را تمام نکرده است،
محدودیت را محاسبه نمی‌کند.

<div dir='rtl'>

---

### دانلود در پس زمینه
</div>

زمانی که شما
wget
را اجرا می‌کنید تا فایلی دانلود کند، فرایند دانلود ترمینال را از شما خواهد گرفت و شما دیگر قادر به
اجرای کامند های جدید نخواهید داشت.
برای اینکه فرایند دانلود به در پس زمینه اجرا شود دو راه وجود دارد.
راه اول استفاده از سوییچ و راه دوم فرستادن پروسه به بکگراند با استفاده از قابلیت
bash

اگر شما از سوییچ استفاده کنید،
wget
برای هر بسته دریافتی یک لاگ هم ذخیره خواهد کرد. در نظر داشته باشید که اگر حتی ترمینال هم بسته شود
wget
باز هم به دانلود ادامه خواهد داد.

```bash
-b,     --background
```

و راه دوم استفاده از علامت
`&`
است.
به این صورت

```bash
wget -i links.txt &
```
دو تفاوت در این روش وجود دارد.

اگر ترمینال را ببندید
wget
هم بسته خواهد شد.

لاگ های این روش کمتر است

<div dir='rtl'>
### میرور کردن سایت
</div>

گاهی شما می‌خواهید تا یک کپی افلاین از یک سایت داشته باشید برای زمانی که دسترسی به اینترنت ندارید آن را
باز هم مشاهده کنید. برای اینکار سوییچ های زیاد وجود دارد که باید هر کدام را بدانید و بر اساس نیازتان
از انها ستفاده کنید/نکنید.

- **دانلود به صورت بازگشتی**

اگر لینکی در صفحه وجود داشته باشد که مارا به صفحه ای دیگر هدایت کند این سوییچ مشخص می‌کند که باید آن را 
دنبال کند.

```bash
-r, --recursive
```

- **عمق پیشرفت در لینک**

در یک سایت ممکن است لینک های زیادی وجود داشته باشد و هر پیج هم باز شامل کلی لینک باشد.
برای جلو گیری از اینکه
wget
تمامی لینک ها را دنبال نکند. درواقع برای اینکه اگر در پیج یک لینک، لینک دیگری وجود داشت و باز هم این روند ادامه داشت،
wget
را از دنبال کردن لینک های هر پیج منع کنیم. باید از سوییچ
`-l`
استفاده کنیم. به صورت پیش فرض عمق 5 است. برای تغییر به بی‌نهایت باید عدد 0 استفاده کرد.

```bash
-l, --level
```

هر دو گزینه بالا برای اینکه یک سایت را میرور کنید به یک سوییچ کوتاه شده اند.

```bash
--mirror
```

این سوییچ، دانلود بازگشتی را فعال و عمق را بی‌نهایت می‌کند.


وقتی سایت شما دانلود شد. شما برای دسترسی به سایت فرضا
index.html
دانلود شده را باز می‌کنید. این فایل از روی سیستم لوکال شما باز می‌شود. اما وقتی روی لینک ها، فایل ها و صفحه هایی
که لینک شده اند بزنید، هیچ کدام از انها از فایل ها لوکال باز نخواهند شد. و از اینترنت خوانده خواهند شد.
برای اینکه فایل ها و صفحه ها به فایل های لوکال دانلود شده لینک شوند باید از سوییچ __تبدیل لینک__ استفاده کنید.

```bash
--convert-links
```

هر صفحه سایت کلی فایل
css
و
js
دارد که صفحه سایت را مناسب و قابل خواندن کند. برای اینکه این فایل های مهم دانلود شود از سوییچ

```bash
--page-requisites
```

استفاده کنید.


و در آخر خلاصه همه دستورات برای میرور کردن سایت.

```bash
wget -mkp
```
<div dir='rtl'>

---

### تنطیم کردن پروکسی
</div>

برای اینکه داده هایمان را از یک پروکسی دریافت کنیم
wget
می‌تواند از پروکسی
http
و
https
پشتیبانی کند. این کار داده هایی که از سرور
ftp
و هم سرور
http
میگیرید را از طریق پروکسی دریافت می‌کند.
برای تنظیم کردن باید از متغییر های محیطی یا
environment variable
ها استفاده کنید. دو متغییر
https_proxy
و
http_proxy
را به آدرس پروکسی سرور تنظیم کنید. برای مثال

```bash
export http_proxy=http://127.0.0.1:8000
export https_proxy=$http_proxy
```

و فقط در زمان استفاده از
wget
باید سوییچ استفاده از پروکسی را فعال کنید

```bash
--proxy
```

<div dir='rtl'>

---

### دانلود فایل با پسونده مشخص
</div>

اگر نیاز بود که فایل هایی با پسوند های مشخصی رو دانلود کنید مثلا فقط
mp3
یا
mp4
باید چند سوییچ رو باهم استفاده کنید تا مشکلی پیش نیاد و در نهایت از سوییچ اصلی اصلی استفاده کنید.

```bash
wget ‐‐level=1 ‐‐recursive ‐‐no-parent ‐‐accept mp3,MP3 http://example.com/mp3/
```

<div dir='rtl'>

- `--no-parent`
برای این استفاده می‌شود که
wget
به پوشه قبلی این دایرکتوری مراجعه نکنه.
</div>

<div dir='rtl'>

- `--accept`
برای این است که در یک لیست که با کاما اجزایش از هم جدا می‌شوند، مشخص کنیم فقط فایل هایی با پسوند هایی که در لیست مشخص کردیم را دانلود کن، و دیگر فایل ها را چشم پوشی کن.
</div>



<div dir='rtl'>

---

#### نکته ها

> 1. حتما لینک ها در کوتیشن قرار بدید، وگرنه ممکن است که بش کاراکتر های لینک را به عنوان وایلدکارد
در نظر بگیرد


> 2. اگر پروسه ها را در بکگراند اجرا می‌کنید و نیاز است لاگ را  همزمان ببینید، کافیست به این روش عمل کنید
> ```bash
> tail -F wget-log
> ```
</div>

---

#### Author or Authors
- arya shabane <m.mohamadshabane@gmail.com>